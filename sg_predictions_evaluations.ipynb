{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys; sys.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import multipletests as fdr\n",
    "from matplotlib import colors\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, r2_score, classification_report\n",
    "from sklearn.linear_model import Ridge, RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, GroupKFold, GroupShuffleSplit, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and clean up ABCD data\n",
    "# set base dirctories\n",
    "ABCD_base_dir   = 'PATH_TO_DIR'\n",
    "ABCD_results_dir   = 'PATH_TO_DIR'\n",
    "\n",
    "#load subj fc data\n",
    "ABCD_fc= pd.read_csv(os.path.join(ABCD_base_dir, 'ABCD_rsfc_withsubcort_5260subj.csv'), header=None)\n",
    "ABCD_fc = ABCD_fc.T\n",
    "ABCD_subj = pd.read_csv(os.path.join(ABCD_base_dir, 'subjects_5260.txt'), header=None, names='s')\n",
    "ABCD_fc.insert(0, \"subjectkey\", ABCD_subj, True)\n",
    "ABCD_fc = ABCD_fc.sort_values(by='subjectkey', ascending=True)\n",
    "\n",
    "# load subj demo and clinical data\n",
    "ABCD_gender_p = pd.read_csv(os.path.join(ABCD_base_dir, 'abcd_pgi01.csv'), header=0)\n",
    "ABCD_gender_y = pd.read_csv(os.path.join(ABCD_base_dir, 'abcd_ygi01.csv'), header=0)\n",
    "\n",
    "#drop duplicate header rows\n",
    "header_row = 0\n",
    "ABCD_gender_p = ABCD_gender_p.drop(header_row)\n",
    "ABCD_gender_y = ABCD_gender_y.drop(header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select subjects for whom we have FC data\n",
    "ABCD_gender_p = ABCD_gender_p[ABCD_gender_p.subjectkey.isin(ABCD_subj.s)]\n",
    "ABCD_gender_y = ABCD_gender_y[ABCD_gender_y.subjectkey.isin(ABCD_subj.s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort data using subjectkey so it's all in the same order\n",
    "ABCD_gender_p = ABCD_gender_p.sort_values(by='subjectkey', ascending=True)\n",
    "ABCD_gender_y = ABCD_gender_y.sort_values(by='subjectkey', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select variables of interest\n",
    "ABCD_gender_y = ABCD_gender_y[['subjectkey', 'sex', 'eventname',\n",
    "                               'gish_m1_y', 'gish_m2_y', \n",
    "                               'gish_f1_y', 'gish_f2_y', \n",
    "                               'gish_m3_y', 'gish_m4_y', \n",
    "                               'gish_f3_y', 'gish_f4_y']]\n",
    "\n",
    "\n",
    "ABCD_gender_p = ABCD_gender_p[['subjectkey', 'sex', 'eventname',\n",
    "                               'gish_m1_p', 'gish_m2_p', 'gish_m3_p', 'gish_m4_p', \n",
    "                               'gish_m5_p', 'gish_m6_p', 'gish_m7_p', 'gish_m8_p', \n",
    "                               'gish_m9_p', 'gish_m10_p', 'gish_m11_p', 'gish_m12_p', \n",
    "                               'gish_m13_p', 'gish_m14_p', \n",
    "                               'gish_f1_p', 'gish_f2_p', 'gish_f3_p', 'gish_f4_p',\n",
    "                               'gish_f5_p', 'gish_f6_p', 'gish_f7_p', 'gish_f8_p', \n",
    "                               'gish_f9_p', 'gish_f10_p', 'gish_f11_p', 'gish_f12_p', \n",
    "                               'gish_f13_p', 'gish_f14_p']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate variables for self-report and parent-report data\n",
    "ABCD_gender_p_f1 = ABCD_gender_p[(ABCD_gender_p.eventname == '1_year_follow_up_y_arm_1')]\n",
    "ABCD_gender_y_f1 = ABCD_gender_y[(ABCD_gender_y.eventname == '1_year_follow_up_y_arm_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data by assigned sex\n",
    "ABCD_gender_p_f1_f = ABCD_gender_p_f1[(ABCD_gender_p_f1.sex =='F')]\n",
    "ABCD_gender_y_f1_f = ABCD_gender_y_f1[(ABCD_gender_y_f1.sex =='F')]\n",
    "ABCD_gender_p_f1_m = ABCD_gender_p_f1[(ABCD_gender_p_f1.sex =='M')]\n",
    "ABCD_gender_y_f1_m = ABCD_gender_y_f1[(ABCD_gender_y_f1.sex =='M')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize all data\n",
    "subj_m = ABCD_gender_y_f1_m.subjectkey\n",
    "subj_f = ABCD_gender_y_f1_f.subjectkey\n",
    "\n",
    "gender_y_f1_m = ABCD_gender_y_f1_m[['gish_m1_y', 'gish_m2_y', 'gish_m3_y', 'gish_m4_y']]\n",
    "gender_y_f1_f = ABCD_gender_y_f1_f[['gish_f1_y', 'gish_f2_y', 'gish_f3_y', 'gish_f4_y']]\n",
    "\n",
    "\n",
    "gender_p_f1_m = ABCD_gender_p_f1_m[['gish_m1_p', 'gish_m2_p', 'gish_m3_p', 'gish_m4_p',\n",
    "                                    'gish_m5_p', 'gish_m6_p', 'gish_m7_p', 'gish_m8_p', \n",
    "                                    'gish_m10_p', 'gish_m12_p', 'gish_m13_p', 'gish_m14_p']]\n",
    "\n",
    "gender_p_f1_f = ABCD_gender_p_f1_f[['gish_f1_p', 'gish_f2_p', 'gish_f3_p', 'gish_f4_p',\n",
    "                                    'gish_f5_p', 'gish_f6_p', 'gish_f7_p', 'gish_f8_p',\n",
    "                                    'gish_f10_p', 'gish_f12_p', 'gish_f13_p', 'gish_f14_p']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove subjects with missing data\n",
    "nanmask = np.isnan(np.double(gender_y_f1_m)).any(axis=1)\n",
    "gender_y_m = gender_y_f1_m[~nanmask]\n",
    "gender_p_m = gender_p_f1_m[~nanmask]\n",
    "subj_m = subj_m[~nanmask]\n",
    "\n",
    "nanmask = np.isnan(np.double(gender_y_f1_f)).any(axis=1)\n",
    "gender_y_f = gender_y_f1_f[~nanmask]\n",
    "gender_p_f = gender_p_f1_f[~nanmask]\n",
    "subj_f = subj_f[~nanmask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove subjects who did not answer the questions\n",
    "nanmask = np.isnan(np.double(gender_p_m)).any(axis=1)\n",
    "gender_y_m = np.double(gender_y_m[~nanmask])\n",
    "gender_p_m = np.double(gender_p_m[~nanmask])\n",
    "subj_m = subj_m[~nanmask]\n",
    "\n",
    "\n",
    "nanmask = np.isnan(np.double(gender_p_f)).any(axis=1)\n",
    "gender_y_f = np.double(gender_y_f[~nanmask])\n",
    "gender_p_f = np.double(gender_p_f[~nanmask])\n",
    "subj_f = subj_f[~nanmask]\n",
    "\n",
    "\n",
    "mask777 = (gender_p_m>=777)\n",
    "mask777 = mask777.any(axis=1)\n",
    "gender_y_m_clean = gender_y_m[~mask777]\n",
    "gender_p_m_clean = gender_p_m[~mask777]\n",
    "subj_m = subj_m[~mask777]\n",
    "\n",
    "\n",
    "mask777 = (gender_p_f>=777)\n",
    "mask777 = mask777.any(axis=1)\n",
    "gender_y_f_clean = gender_y_f[~mask777]\n",
    "gender_p_f_clean = gender_p_f[~mask777]\n",
    "subj_f = subj_f[~mask777]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the sum to get summary self- and parent- report scores\n",
    "gender_y_m_sum = np.sum(gender_y_m_clean, axis=1)\n",
    "gender_y_f_sum = np.sum(gender_y_f_clean, axis=1)\n",
    "gender_p_m_sum = np.sum(gender_p_m_clean, axis=1)\n",
    "gender_p_f_sum = np.sum(gender_p_f_clean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data on site \n",
    "ABCD_site = pd.read_csv(os.path.join(ABCD_base_dir, 'abcd_lt01.csv'), header=0)\n",
    "ABCD_site = ABCD_site.drop(header_row)\n",
    "ABCD_site_f1 = ABCD_site[ABCD_site.eventname == 'baseline_year_1_arm_1']\n",
    "ABCD_site_f1 = ABCD_site_f1.sort_values(by='subjectkey', ascending=True)\n",
    "ABCD_site_f1 = ABCD_site_f1[['subjectkey', 'site_id_l']]\n",
    "ABCD_site_f1.reset_index(inplace=True) \n",
    "\n",
    "\n",
    "site_m = ABCD_site_f1[ABCD_site_f1.subjectkey.isin(subj_m)].site_id_l\n",
    "site_f = ABCD_site_f1[ABCD_site_f1.subjectkey.isin(subj_f)].site_id_l\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site names\n",
    "sites = ['Colorado Boulder',\n",
    "         'Florida International',\n",
    "         'Laureate Institute',\n",
    "         'Medical University of South Carolina',\n",
    "         'Oregon Health and Science University',\n",
    "         'University of Rochester',\n",
    "         'Stanford Research Institute International',\n",
    "         'University of California - Los Angeles',\n",
    "         'University of California - San Diego',\n",
    "         'University of Florida',\n",
    "         'University of Maryland Baltimore',\n",
    "         'University of Michigan',\n",
    "         'University of Minnesota',\n",
    "         'University of Pittsburgh',\n",
    "         'University of Utah',\n",
    "         'University of Wisconsin-Milwaukee',\n",
    "         'Washington University St.Louis',\n",
    "         'Yale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove data from specific sites with fewer than 10 subjects\n",
    "site_mask = site_m.values!=('site22')\n",
    "site_m = site_m[site_mask]\n",
    "subj_m = subj_m[site_mask]\n",
    "gender_y_m_sum = gender_y_m_sum[site_mask]\n",
    "gender_p_m_sum = gender_p_m_sum[site_mask]\n",
    "\n",
    "site_mask = site_m.values!=('site19')\n",
    "site_m = site_m[site_mask]\n",
    "subj_m = subj_m[site_mask]\n",
    "gender_y_m_sum = gender_y_m_sum[site_mask]\n",
    "gender_p_m_sum = gender_p_m_sum[site_mask]\n",
    "\n",
    "site_mask = site_f.values!=('site22')\n",
    "site_f = site_f[site_mask]\n",
    "subj_f = subj_f[site_mask]\n",
    "gender_y_f_sum = gender_y_f_sum[site_mask]\n",
    "gender_p_f_sum = gender_p_f_sum[site_mask]\n",
    "\n",
    "site_mask = site_f.values!=('site19')\n",
    "site_f = site_f[site_mask]\n",
    "subj_f = subj_f[site_mask]\n",
    "gender_y_f_sum = gender_y_f_sum[site_mask]\n",
    "gender_p_f_sum = gender_p_f_sum[site_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in FC data\n",
    "ABCD_fc= pd.read_csv(os.path.join(ABCD_base_dir, 'ABCD_rsfc_withsubcort_5260subj.csv'), header=None)\n",
    "ABCD_fc = ABCD_fc.T\n",
    "ABCD_subj = pd.read_csv(os.path.join(ABCD_base_dir, 'subjects_5260.txt'), header=None, names='s')\n",
    "ABCD_fc.insert(0, \"subjectkey\", ABCD_subj, True)\n",
    "ABCD_fc = ABCD_fc.sort_values(by='subjectkey', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate by assigned sex\n",
    "fc_m = ABCD_fc[ABCD_fc.subjectkey.isin(subj_m)]\n",
    "fc_f = ABCD_fc[ABCD_fc.subjectkey.isin(subj_f)]\n",
    "\n",
    "fc_m.reset_index(inplace=True) \n",
    "fc_m = fc_m.drop(columns=['index', 'subjectkey'])\n",
    "\n",
    "fc_f.reset_index(inplace=True) \n",
    "fc_f = fc_f.drop(columns=['index', 'subjectkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up predictive models\n",
    "#number of repetitions you want to perform (100 for 'true', 1000 for 'null')\n",
    "rep = 100\n",
    "\n",
    "#number of folds you want in the cross-validation\n",
    "k = 3\n",
    "#proportion of data you want in your training set and test set\n",
    "train_size = .80\n",
    "test_size = 1-train_size\n",
    "\n",
    "#regression model type\n",
    "regr = Ridge(normalize=True, max_iter=1000000, solver='lsqr')\n",
    "#set hyperparameter grid space you want to search through for the model\n",
    "#adapted from the Thomas Yeo Lab Github: \n",
    "#ThomasYeoLab/CBIG/blob/master/stable_projects/predict_phenotypes/He2019_KRDNN/KR_HCP/CBIG_KRDNN_KRR_HCP.m\n",
    "#alphas = [0, 0.00001, 0.0001, 0.001, 0.004, 0.007, 0.01, 0.04, 0.07, 0.1, 0.4, 0.7, 1, 1.5, 2, 2.5, 3,\n",
    "#          3.5, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 150, 200, 300, 500, 700, 1000, 2000, \n",
    "#          3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, \n",
    "          150, 200, 300, 500, 700, 1000]\n",
    "\n",
    "#alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "#param grid set to the hyperparamters you want to search through\n",
    "paramGrid ={'alpha': alphas}\n",
    "\n",
    "#set x data to be the input variable you want to use\n",
    "X = fc_f.values\n",
    "Y = gender_p_f_sum.T\n",
    "site = site_f.values\n",
    "\n",
    "#number of features \n",
    "n_feat = X.shape[1]\n",
    "\n",
    "pred_name = 'parent_report'\n",
    "pred_sex = 'f'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variables to store relevant data/outputs\n",
    "#r^2 - coefficient of determination\n",
    "r2 = np.zeros([rep])\n",
    "#explained variance\n",
    "var = np.zeros([rep])\n",
    "#correlation between true and predicted (aka prediction accuracy)\n",
    "corr = np.zeros([rep])\n",
    "#optimised alpha (hyperparameter)\n",
    "opt_alpha = np.zeros([rep])\n",
    "#predictions made by the model\n",
    "#don't need to save any of these right now\n",
    "#preds = np.zeros([rep,n_cog,int(np.ceil(X.shape[0]*test_size))])\n",
    "#true test values for cognition\n",
    "#cogtest = np.zeros([rep,n_cog,int(np.ceil(X.shape[0]*test_size))])\n",
    "#feature importance extracted from the model\n",
    "featimp = np.zeros([rep,n_feat])\n",
    "#for when the feat weights get haufe-inverted\n",
    "#featimp_haufe = np.zeros([rep,n_feat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through the diff train/test splits\n",
    "\n",
    "#alphas = np.load(results_dir + '/fc_alpha_' + pred_name + '_opt.npy') ##only need this for the null ones\n",
    "\n",
    "for p in range(rep):\n",
    "    \n",
    "    #print model # you're on\n",
    "    print('Model %d' %(p+1))\n",
    "    \n",
    "    #Y_shuffle = shuffle(Y, random_state=p) ##only need this for the null ones\n",
    "    \n",
    "    #print time\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    \n",
    "    #split into train/test data\n",
    "    train_inds, test_inds = next(GroupShuffleSplit(test_size=1-train_size, n_splits=1, random_state = p).split(X, groups=site))\n",
    "    \n",
    "    #set x values based on indices from split\n",
    "    x_train = X[train_inds]\n",
    "    x_test = X[test_inds]\n",
    "        \n",
    "    #set y values based on indices from split  \n",
    "    beh_train = Y[train_inds]\n",
    "    beh_test = Y[test_inds]\n",
    "    \n",
    "    #set y values based on indices from split ##only need this for the null ones\n",
    "    #beh_train = Y_shuffle[train_inds]\n",
    "    #beh_test = Y_shuffle[test_inds]\n",
    "    \n",
    "    site_train = site[train_inds]\n",
    "    site_test = site[test_inds] \n",
    "    \n",
    "    #convert y values to to double\n",
    "    y_train = np.double(beh_train)\n",
    "    y_test = np.double(beh_test)\n",
    "\n",
    "\n",
    "\n",
    "    #create variables to store nested CV scores, and best parameters from hyperparameter optimisation\n",
    "    best_scores = []\n",
    "    best_params = []\n",
    "    \n",
    "\n",
    "        \n",
    "    #set parameters for inner and outer loops for CV\n",
    "    cv_split = GroupKFold(n_splits=k)\n",
    "        \n",
    "    print (\"Optimising Models\")\n",
    "            \n",
    "    #define regressor with grid-search CV for inner loop\n",
    "    gridSearch = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1, verbose=0, cv=cv_split, scoring='explained_variance')\n",
    "\n",
    "    #fit regressor to the model, use site ID as group category again\n",
    "    gridSearch.fit(x_train, y_train, groups=site_train)\n",
    "\n",
    "    #save parameters corresponding to the best score\n",
    "    best_params.append(list(gridSearch.best_params_.values()))\n",
    "    best_scores.append(gridSearch.best_score_)\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    print (\"Evaluating Models\")\n",
    "        \n",
    "    #save optimised alpha values\n",
    "    opt_alpha[p] = best_params[best_scores.index(np.max(best_scores))][0]\n",
    "    \n",
    "    \n",
    "    #rand_alpha = np.random.choice(alphas)\n",
    "    \n",
    "    #fit optimized models\n",
    "    model = Ridge(alpha = opt_alpha[p], normalize=True, max_iter=1000000, solver='lsqr')\n",
    "    #model = Ridge(alpha = rand_alpha, normalize=True, max_iter=1000000, solver='lsqr')\n",
    "\n",
    "    model.fit(x_train, y_train);\n",
    "        \n",
    "        \n",
    "    #evaluate model\n",
    "    r2[p]=model.score(x_test,y_test)\n",
    "    print(r2[p])\n",
    "        \n",
    "    #generate predictions in test set\n",
    "    preds = []\n",
    "    preds = model.predict(x_test).ravel()\n",
    "    \n",
    "        \n",
    "    #compute explained variance \n",
    "    var[p] = explained_variance_score(y_test, preds)\n",
    "    print(var[p])\n",
    "\n",
    "\n",
    "    #compute correlation between true and predicted (prediction accuracy)\n",
    "    corr[p] = np.corrcoef(y_test.ravel(), preds)[1,0]\n",
    "    print(corr[p])\n",
    "    \n",
    "    #print (\"Haufe-Transforming Feature Weights\")\n",
    "    cov_x = []\n",
    "    cov_y = []\n",
    "    \n",
    "    #extract feature importance\n",
    "    featimp[p,:] = model.coef_\n",
    "    #compute Haufe-inverted feature weights\n",
    "    cov_x = np.cov(np.transpose(x_train))\n",
    "    cov_y = np.cov(y_train)\n",
    "    featimp_haufe[p,:] = np.matmul(cov_x,featimp[p,:])*(1/cov_y)\n",
    "        \n",
    "\n",
    "        \n",
    "    #save results\n",
    "    np.save((results_dir + '/fc_r2_' + pred_name + pred_sex + '.npy'),r2)\n",
    "    np.save((results_dir + '/fc_var_' + pred_name + pred_sex + '.npy'),var)\n",
    "    np.save((results_dir + '/fc_corr_' + pred_name + pred_sex + '.npy'),corr)\n",
    "    np.save((results_dir + '/fc_alpha_' + pred_name + pred_sex + '.npy'),opt_alpha)\n",
    "    np.save((results_dir + '/fc_featimp_' + pred_name + pred_sex + '.npy'),featimp)\n",
    "    np.save((results_dir + '/fc_featimp_haufe_' + pred_name + pred_sex + '.npy'),featimp_haufe_f)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
